#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Google Aistudio èŠå¤©è®°å½•è½¬ Markdown æ–‡æ¡£å·¥å…·
åŠŸèƒ½ï¼šè§£æ Aistudio å¯¼å‡ºçš„ JSON æ ¼å¼èŠå¤©è®°å½•ï¼Œè½¬æ¢ä¸ºå¯è¯»çš„ Markdown æ–‡æ¡£
"""

import json
import os
from pathlib import Path
from datetime import datetime


class AistudioChatParser:
    """Aistudio èŠå¤©è®°å½•è§£æå™¨"""

    def __init__(self):
        self.role_map = {
            'user': ('ç”¨æˆ·', 'ğŸ‘¤'),
            'model': ('AIåŠ©æ‰‹', 'ğŸ¤–')
        }

    def load_chat_file(self, file_path: str) -> dict:
        """åŠ è½½å¹¶è§£æ JSON æ–‡ä»¶"""
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)

    def extract_chunks(self, data: dict) -> list:
        """æå–å¯¹è¯å†…å®¹å—"""
        if 'chunkedPrompt' in data and 'chunks' in data['chunkedPrompt']:
            return data['chunkedPrompt']['chunks']
        return []

    def clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬ä¸­çš„ç‰¹æ®Šå­—ç¬¦å’Œæ ¼å¼é—®é¢˜"""
        if not text:
            return ''
        text = text.strip()
        text = text.replace('\r\n', '\n').replace('\r', '\n')
        while '\n\n\n' in text:
            text = text.replace('\n\n\n', '\n\n')
        return text

    def format_message(self, chunk: dict, index: int) -> str:
        """æ ¼å¼åŒ–å•æ¡æ¶ˆæ¯ä¸º Markdown æ ¼å¼"""
        role = chunk.get('role', 'unknown')
        role_name, role_icon = self.role_map.get(role, ('æœªçŸ¥', 'â“'))

        text = self.clean_text(chunk.get('text', ''))
        token_count = chunk.get('tokenCount', 0)

        is_thought = chunk.get('isThought', False)
        finish_reason = chunk.get('finishReason', '')

        parts = chunk.get('parts', [])
        if parts and len(parts) > 1:
            main_text = ''
            for part in parts:
                if isinstance(part, dict):
                    part_text = part.get('text', '')
                    if part.get('thought', False):
                        continue
                    main_text += part_text
                else:
                    main_text += str(part)
            if main_text.strip():
                text = self.clean_text(main_text)

        if not text:
            return ''

        lines = [
            f'### {role_icon} {role_name}',
            '',
            text,
            ''
        ]

        metadata = []
        if token_count > 0:
            metadata.append(f'Tokens: {token_count}')
        if finish_reason:
            metadata.append(f'ç»“æŸåŸå› : {finish_reason}')

        if metadata:
            lines.append(f'<details><summary>å…ƒæ•°æ®</summary>')
            lines.append('')
            lines.append(' | '.join(metadata))
            lines.append('')
            lines.append('</details>')
            lines.append('')

        return '\n'.join(lines)

    def convert_to_markdown(self, data: dict, title: str = "èŠå¤©è®°å½•") -> str:
        """å°†è§£æåçš„æ•°æ®è½¬æ¢ä¸º Markdown æ ¼å¼"""
        chunks = self.extract_chunks(data)

        if not chunks:
            return "# èŠå¤©è®°å½•\n\n> æ— å¯¹è¯å†…å®¹"

        lines = [
            f'# {title}',
            '',
            f'> å¯¼å‡ºæ—¶é—´: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}',
            '',
            '---',
            ''
        ]

        model_thought_buffer = []
        last_was_model_thought = False

        for i, chunk in enumerate(chunks):
            role = chunk.get('role', 'unknown')
            is_thought = chunk.get('isThought', False)

            if is_thought and role == 'model':
                thought_text = self.clean_text(chunk.get('text', ''))
                if thought_text:
                    model_thought_buffer.append(thought_text)
                last_was_model_thought = True
                continue

            if model_thought_buffer and not is_thought:
                lines.append('> **ğŸ¤” AI æ€è€ƒè¿‡ç¨‹ï¼š**')
                lines.append('>')
                for thought in model_thought_buffer:
                    thought_lines = thought.split('\n')
                    for tline in thought_lines:
                        lines.append(f'> {tline}')
                    lines.append('>')
                lines.append('')
                model_thought_buffer = []
                last_was_model_thought = False

            message = self.format_message(chunk, i)
            if message:
                lines.append(message)
                lines.append('---')
                lines.append('')

        return '\n'.join(lines)

    def process_file(self, input_path: str, output_dir: str = None) -> str:
        """å¤„ç†å•ä¸ªæ–‡ä»¶"""
        input_file = Path(input_path)
        if not input_file.exists():
            raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")

        if output_dir is None:
            output_dir = input_file.parent

        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        data = self.load_chat_file(input_path)

        title = input_file.stem
        markdown_content = self.convert_to_markdown(data, title)

        output_path = output_dir / f"{input_file.stem}.md"
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(markdown_content)

        return str(output_path)

    def process_multiple_files(self, file_paths: list, output_dir: str = None) -> list:
        """æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶"""
        results = []
        for file_path in file_paths:
            try:
                output = self.process_file(file_path, output_dir)
                results.append((file_path, output, True, None))
                print(f"âœ… æˆåŠŸè½¬æ¢: {file_path} -> {output}")
            except Exception as e:
                results.append((file_path, None, False, str(e)))
                print(f"âŒ è½¬æ¢å¤±è´¥: {file_path} - {str(e)}")
        return results


def main():
    """ä¸»å‡½æ•°"""
    parser = AistudioChatParser()

    input_files = [
        r"d:\202508\å¼€å‘\aisuidiochat2md\aisuidiochat2md\Husband's Wife's Emotional Distress",
        r"d:\202508\å¼€å‘\aisuidiochat2md\aisuidiochat2md\Mind Quadrant_ Inner World Assessment"
    ]

    output_directory = r"d:\202508\å¼€å‘\aisuidiochat2md\aisuidiochat2md\output"

    print("=" * 60)
    print("Google Aistudio èŠå¤©è®°å½•è½¬ Markdown å·¥å…·")
    print("=" * 60)
    print()

    results = parser.process_multiple_files(input_files, output_directory)

    print()
    print("=" * 60)
    print("å¤„ç†ç»“æœæ±‡æ€»:")
    print("=" * 60)
    for input_path, output_path, success, error in results:
        status = "âœ… æˆåŠŸ" if success else "âŒ å¤±è´¥"
        print(f"{status}: {input_path}")
        if output_path:
            print(f"   è¾“å‡º: {output_path}")
        if error:
            print(f"   é”™è¯¯: {error}")

    print()
    print("âœ¨ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼")


if __name__ == "__main__":
    main()
